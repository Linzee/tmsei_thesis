%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% I, the copyright holder of this work, release this work into the
%% public domain. This applies worldwide. In some countries this may
%% not be legally possible; if so: I grant anyone the right to use
%% this work for any purpose, without any conditions, unless such
%% conditions are required by law.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Content:

%  general
%   Similarity
%   Programming environments
%   Possible usage
%   Metric types
%   (Scicentific) Question, Goal
% data specific
%   Robotanik
%   Evaluation
%   Collecting expert data
% implementation specific
%   my metrics
%   Tool
%   Data Format

\documentclass[
  digital, %% This option enables the default options for the
           %% digital version of a document. Replace with `printed`
           %% to enable the default options for the printed version
           %% of a document.
  table,   %% Causes the coloring of tables. Replace with `notable`
           %% to restore plain tables.
  lof,     %% Prints the List of Figures. Replace with `nolof` to
           %% hide the List of Figures.
  lot,     %% Prints the List of Tables. Replace with `nolot` to
           %% hide the List of Tables.
  %% More options are listed in the user guide at
  %% <http://mirrors.ctan.org/macros/latex/contrib/fithesis/guide/mu/fi.pdf>.
]{fithesis3}
%% The following section sets up the locales used in the thesis.
\usepackage[resetfonts]{cmap} %% We need to load the T2A font encoding
\usepackage[T1,T2A]{fontenc}  %% to use the Cyrillic fonts with Russian texts.
\usepackage[
  main=english, %% By using `czech` or `slovak` as the main locale
                %% instead of `english`, you can typeset the thesis
                %% in either Czech or Slovak, respectively.
  english, german, russian, czech, slovak %% The additional keys allow
]{babel}        %% foreign texts to be typeset as follows:
%%
%%   \begin{otherlanguage}{german}  ... \end{otherlanguage}
%%   \begin{otherlanguage}{russian} ... \end{otherlanguage}
%%   \begin{otherlanguage}{czech}   ... \end{otherlanguage}
%%   \begin{otherlanguage}{slovak}  ... \end{otherlanguage}
%%
%% For non-Latin scripts, it may be necessary to load additional
%% fonts:
\usepackage{paratype}
\def\textrussian#1{{\usefont{T2A}{PTSerif-TLF}{m}{rm}#1}}
%%
%% The following section sets up the metadata of the thesis.
\thesissetup{
    date          = \the\year/\the\month/\the\day,
    university    = mu,
    faculty       = fi,
    type          = bc,
    author        = Dominik Gmiterko,
    gender        = m,
    advisor       = John Smith,
    title         = {Similarity of programming problems},
    TeXtitle      = {Similarity of programming problems},
    keywords      = {similarity, metrics, programming, keyword2, ...},
    TeXkeywords   = {similarity, metrics, programming, keyword2, \ldots},
    abstract      = {This is the abstract of my thesis, which can

                     span multiple paragraphs.},
    thanks        = {These are the acknowledgements for my thesis, which can

                     span multiple paragraphs.},
    bib           = thesis.bib,
}
\usepackage{makeidx}      %% The `makeidx` package contains
\makeindex                %% helper commands for index typesetting.
%% These additional packages are used within the document:
\usepackage{paralist} %% Compact list environments
\usepackage{amsmath}  %% Mathematics
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}      %% Hyperlinks
\usepackage{markdown} %% Lightweight markup
\usepackage{listings} %% Source code highlighting
\lstset{
  basicstyle      = \ttfamily,%
  identifierstyle = \color{black},%
  keywordstyle    = \color{blue},%
  keywordstyle    = {[2]\color{cyan}},%
  keywordstyle    = {[3]\color{olive}},%
  stringstyle     = \color{teal},%
  commentstyle    = \itshape\color{magenta}}
\usepackage{floatrow} %% Putting captions above tables
\floatsetup[table]{capposition=top}
\begin{document}
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

Define a metric for measuring similarity of programming problems
for introductory programming

\begin{markdown*}{%
  hybrid,
  definitionLists,
  footnotes,
  inlineFootnotes,
  hashEnumerators,
  fencedCode,
  citations,
  citationNbsps,
}

%
% Introduction
%

% TODO co je citatelov ciel, na co sa moze tesit

%
% 1. General, about similarity of programming problems
%

# Similarity

There is a lot of research about similarity in many different fields like bioinformatics (sequence alignment, similarity matrix of proteins), data retrieval (document similarity), plagiarism detection and many more. On other hand there is only a few mentions about comparing programming problems currently published.

recommender systems

duplicated code
plagiarism - modified to disguise plagiarism

% TODO
not problmes but source code similarity -> plagiatorism ~[@beth2014comparison], source quality control ~[@]

% TODO?
% CITE from similarity techniques:
% The abstract nature of computer source code, however, limits the feasibility of applying such tools to computational artifacts
%...different approaches has to be used
% possible ambiguities in program semantics, other features, such as arbitrary identifier names, variable whitespace, and nonlinear sequencing of code, present difficulties in textual similarity analysis unique to program source code.
% TODO
"leveraging human intelligence‚Äù instead of its use for automatic intelligent method ~[@baker2016stupid]



## Programming environments

In this section we would like to define what programming environment and programming problems are for us.

When we talk about programming problems we in most cases mean problems created for interactive programming environments for introductory programming. Some examples of environments are [Robotanik](https://tutor.fi.muni.cz/), [Karel](http://stanford.edu/~cpiech/karel/ide.html), Lightbot.

Problems in this environments are specified by grid with tiles which have different meaning. Users are supposed to write program for some entity to fulfil given task. Most common task is to visit all tiles of some type. In Robotanik student are asked to build program guiding robot to collect all flowers.

Some programming environments try to constrain student in order to produce more creative solutions. One possible limitation is allowing student to use only subset of all available commands. Another approach is to limit length of program.

## Possible usage

When we define metrics for measuring similarity of programming problems we can use them for different purposes. Most of them are useful for adaptive programming environments. First possible usage is recommendation of problems for student to solve. We do not want to recommend very similar problems to those that were solved without any problems. However when student struggled system should recommend more of similar problems.

% TODO

When hints ~[@hosseini2017study]

% TODO A study of concept-based similarity approaches for recommending program examples

% TODO This can be more general

Another idea I am quite found of is automatic construction of user interface. When we have large amount of problems without any present categorization we can use problem similarity to construct categories for student to select from.

clusters can serve as a basis for knowledge component  definition  or  refinemen ~[@pelanek2017measuring]

Authors of systems can use our metrics for gaining insight of problem pool. It is possible to detect redundant problems, maybe even tell which problems are missing. One way of achieving this is plotting problems to plane and displaying it to author.

## Metric types

% TODO microtrailer

### Data

We can define different metrics for comparing programming problems. It is possible to divide metrics into 4 categories based on data used.

**Problem statement** in interactive programming environments can be used to collect features used in problem. Similarity is mostly computed using distance of vectors describing some features of problem. This category includes usage of tiles in problem, allowed commands, size of level, and more.

**Manual labeling** provides us with information not directly related to problem statement but specific for each problem. Some examples of this data are division of problems to categories or levels, difficulty of problem. We are not interested in using this kind of data alone, but they can by used to aid in some other metric.

**Solution** based metrics differ greatly with method used by users to input solutions. We can divide them to textual and visual programming languages. Commonly used programming languages like Python or Java are text-based. Hovever some programming environments for the sake of simplicity use alternative approach. E.g. Robotanik uses commands (blocks) that can be placed in rows representing functions. Programming enthronements Robomise and Scratch use [Blockly](https://developers.google.com/blockly/) (like) user interface where user builds trees from predefined nested blocks.

When dealing with solutions we usually have more than one example solution. This means we may want to somehow extended metrics to use solutions from all students their attempts. Simplest way is to average of calculated features. We will talk more about computing features in next section.

**Performance based** metrics requires having collected data about students while solving problems. Example of data that falls in this category is solution time, number of attempts, hints used. Metrics using performance data are widely applicable to many systems ~[@pelanek2017measuring]

**Combined** metrics may produce more accurate results with smaller amount of data. But it is harder to construct and evaluate them. We will talk more about them in later chapters.

### Similarity techniques

Following section will discuss different techniques used to compute similarity of two problems using data described in previous section.

Many similarity techniques are based on edit distance. Similarity is then typically specified as $1/{1+d}$ where $d$ is edit distance. Then edit distance is defined as minimum number of operations necessary to transform one instance of structure to another.

*Text/token-based* techniques can be applied to data describing **problem statement** and **solution**. We can use different techniques known from information retrieval. Sometimes it is required to modify this standard techniques when using with data from visual programming environments.

One of simplest methods is using bag-of-words. In our problems we can either count occurrences of each tile type used in problem statement or commands used in solution. Many of text-based techniques can be applied to multiple sources of data. In either case we will end up with vector of features describing data. This means we have to apply additional step to retrieve similarity of two problems. This step will be applying some distance metric on pairs of feature vectors. Some possible similarity metrics are Euclidean similarity and Cosine similarity.

Edit distances can also be applied to different kind of data. When analyzing text we can use Levenshtein distance which can be used to directly compare two problems.

Also techniques mostly used in plagiarism detection like w-shingling and winnowing ~[@schleimer2003winnowing] may be used.

There are many other more complex information retrieval and natural language processing techniques. However wont be using them in this work because solutions in Robotanik are really short and we think more complex techniques can't give us any significant benefit.

*Tree-based* techniques are often used in measuring source code similarity using Abstract syntax trees (AST). We can compute similarity of two trees as their tree edit distance.

*Graph-based* techniques may also use edit distance or some other metrics describing graphs. For **solutions** we can generate program dependence graphs (PDG)~[@davey1995development], control flow graphs (CFG).

## Goal

In the rest of the thesis we will try to answer several questions:

- What types of metric can be used on data available from tutoring system Robotanik.

- Do different metrics correlate? Do they measure different aspects of problem similarity or is there one underlying common similarity? If there are multiple aspects, what is the relation between them? How do we use them in practical applications?

- Implement simple tool which will be able to ease comparing grid based problems and their solutions.

%
% 2. Data specific
%

# Robotanik

Most of the experiments were executed on data collected from programming environment Robotanik available at [tutor.fi.muni.cz](http://tutor.fi.muni.cz/). Robotanik is programming environment with 78 handcrafted problems for student to solve. Goal of the student is to write program for robot to traverse board and collect all flowers. Each problem has board filled with tiles of stones, colored tiles (green, red, brown) and flowers.

**Problem statements**

**Solutions**

**Performance data**

## Chosen metrics

In this thesis we are consider only some metrics. We will describe them in detail in this chapter.

### Problem statement

### Solutions

### Performance data


%
% 3. Implementation specific
%

# Tool

## Tool capabilities

## Chosen metrics

## Evaluation

### Compare metrics

### Collecting crowd-truth

## Visualisations

\end{markdown*}

  \makeatletter\thesis@blocks@clear\makeatother
  \phantomsection %% Print the index and insert it into the
  \addcontentsline{toc}{chapter}{\indexname} %% table of contents.
  \printindex

\appendix %% Start the appendices.
\chapter{An appendix}
Here you can insert the appendices of your thesis.

\end{document}
